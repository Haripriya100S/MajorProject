{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "121e29fc",
   "metadata": {},
   "source": [
    "# IMPORTING THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13ffa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\python310\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from SpeechRecognition) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7e4cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python310\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b77c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675311e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4206899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "import time\n",
    "import difflib\n",
    "import numpy\n",
    "import keras\n",
    "import tensorflow\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de6a5e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5754f3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ac763",
   "metadata": {},
   "source": [
    "# PRE- PROCESSING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45526ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"intents (1).json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "try:\n",
    "    with open(\"data.pickle\", \"rb\") as f:\n",
    "        words, labels, training, output = pickle.load(f)\n",
    "except:\n",
    "    words = []\n",
    "    labels =[]\n",
    "    docs_patt = []\n",
    "    docs_tag = []\n",
    "\n",
    "#TOKENISATION & STEMMING\n",
    "    for intent in data[\"intents\"]:\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            wrds = nltk.word_tokenize(pattern)\n",
    "            for item in wrds:\n",
    "                words.extend(wrds)\n",
    "                docs_patt.append(wrds)\n",
    "                docs_tag.append(intent[\"tag\"])\n",
    "                if intent[\"tag\"] not in labels:\n",
    "                    labels.append(intent[\"tag\"])\n",
    "    words = [stemmer.stem(w.lower()) for w in words]\n",
    "    words = sorted(list(set(words)))\n",
    "    labels = sorted(labels)\n",
    "\n",
    "    training = []\n",
    "    output = []\n",
    "\n",
    "    out_empty = [0 for _ in range(len(labels))]\n",
    "# BAG OF WORDS - FEATURE ENGINEERING\n",
    "    for x, doc in enumerate(docs_patt):\n",
    "        bag = []\n",
    "        wrds = [stemmer.stem(w.lower()) for w in doc]\n",
    "        for w in words:\n",
    "            if w in wrds:\n",
    "                bag.append(1)\n",
    "            else:\n",
    "                bag.append(0)\n",
    "        output_row = out_empty[:]\n",
    "        output_row[labels.index(docs_tag[x])] = 1\n",
    "\n",
    "        training.append(bag)\n",
    "        output.append(output_row)\n",
    "\n",
    "    training = numpy.array(training)\n",
    "    output = numpy.array(output)\n",
    "\n",
    "    with open(\"data.pickle\", \"wb\") as f:\n",
    "        pickle.dump((words, labels, training, output), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0a4476",
   "metadata": {},
   "source": [
    "# MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6bfbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer with the shape of your input data\n",
    "model.add(Dense(units=8, input_shape=(len(training[0]),), activation='relu'))\n",
    "\n",
    "# Add hidden layers\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=len(output[0]), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f55ba2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try loading the model, and if it doesn't exist, train and save it\n",
    "try:\n",
    "    model.load_weights(\"model.keras\")\n",
    "except:\n",
    "    history = model.fit(training, output, epochs=100, batch_size=8, verbose=1)\n",
    "    model.save_weights(\"model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dcef15",
   "metadata": {},
   "source": [
    "# INPUT PRE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f88df1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "\n",
    "    return numpy.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e8599cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_list(s):\n",
    "    a = []\n",
    "    ns = \"\"\n",
    "    s = s + \" \" \n",
    "    for i in range(len(s)):\n",
    "        if s[i] == \" \":\n",
    "            a.append(ns)\n",
    "            ns = \"\"\n",
    "        else:\n",
    "            ns = ns + s[i]\n",
    "    a = list(set(a))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "951a913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the file in this fuction to create a dictionary of unique vocabulary\n",
    "def json_to_dictionary(data):\n",
    "    dictionary = []\n",
    "    fil_dict= []\n",
    "    vocalubary = []\n",
    "    for i in data[\"intents\"]:\n",
    "        for pattern in i[\"patterns\"]:\n",
    "            vocalubary.append(pattern.lower())\n",
    "    for i in vocalubary:\n",
    "        dictionary.append(words_to_list(i))\n",
    "    for i in range(len(dictionary)):\n",
    "        for word in dictionary[i]:\n",
    "            fil_dict.append(word)\n",
    "    return list(set(fil_dict))\n",
    "\n",
    "# this fuction checks the spelling in the sentence\n",
    "chatbot_vocabulary = json_to_dictionary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82c8db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_checker(s):\n",
    "    correct_string = \"\"\n",
    "    for word in s.casefold().split():\n",
    "        if word not in chatbot_vocabulary:\n",
    "            suggestion = difflib.get_close_matches(word, chatbot_vocabulary)\n",
    "            for x in suggestion:\n",
    "                pass\n",
    "            if len(suggestion) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                correct_string = correct_string + \" \" + str(suggestion[0])\n",
    "        else:\n",
    "            correct_string = correct_string + \" \" + str(word)\n",
    "\n",
    "    return correct_string "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bfb4f8",
   "metadata": {},
   "source": [
    "# SPEECH RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d268729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement speech_recognition (from versions: none)\n",
      "ERROR: No matching distribution found for speech_recognition\n"
     ]
    }
   ],
   "source": [
    "##ignore\n",
    "pip install speech_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69f1076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyttsx3\n",
      "  Downloading pyttsx3-2.90-py3-none-any.whl (39 kB)\n",
      "Collecting comtypes (from pyttsx3)\n",
      "  Obtaining dependency information for comtypes from https://files.pythonhosted.org/packages/c2/a7/fe4bd49b5c4afa7a7ed3852abda6909e48c00715e6a134e47055381113aa/comtypes-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading comtypes-1.2.0-py2.py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pypiwin32 (from pyttsx3)\n",
      "  Downloading pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\hari priya\\appdata\\roaming\\python\\python310\\site-packages (from pyttsx3) (306)\n",
      "Downloading comtypes-1.2.0-py2.py3-none-any.whl (184 kB)\n",
      "   ---------------------------------------- 0.0/184.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/184.3 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 30.7/184.3 kB ? eta -:--:--\n",
      "   -------- ------------------------------ 41.0/184.3 kB 495.5 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 41.0/184.3 kB 495.5 kB/s eta 0:00:01\n",
      "   ----------------- --------------------- 81.9/184.3 kB 416.7 kB/s eta 0:00:01\n",
      "   ----------------- --------------------- 81.9/184.3 kB 416.7 kB/s eta 0:00:01\n",
      "   ----------------- --------------------- 81.9/184.3 kB 416.7 kB/s eta 0:00:01\n",
      "   ------------------- ------------------- 92.2/184.3 kB 291.5 kB/s eta 0:00:01\n",
      "   ------------------- ------------------- 92.2/184.3 kB 291.5 kB/s eta 0:00:01\n",
      "   ------------------- ------------------- 92.2/184.3 kB 291.5 kB/s eta 0:00:01\n",
      "   ------------------- ------------------- 92.2/184.3 kB 291.5 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 112.6/184.3 kB 204.8 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 112.6/184.3 kB 204.8 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 122.9/184.3 kB 185.0 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 122.9/184.3 kB 185.0 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 122.9/184.3 kB 185.0 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 143.4/184.3 kB 177.5 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 143.4/184.3 kB 177.5 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 143.4/184.3 kB 177.5 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 163.8/184.3 kB 172.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ -- 174.1/184.3 kB 88.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ -- 174.1/184.3 kB 88.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ -- 174.1/184.3 kB 88.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ -- 174.1/184.3 kB 88.8 kB/s eta 0:00:01\n",
      "   --------------------------------------- 184.3/184.3 kB 85.0 kB/s eta 0:00:00\n",
      "Installing collected packages: comtypes, pypiwin32, pyttsx3\n",
      "Successfully installed comtypes-1.2.0 pypiwin32-223 pyttsx3-2.90\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd51845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "r=sr.Recognizer()\n",
    "import pyttsx3\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f5e8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_speaking(message):\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "    if engine._inLoop:\n",
    "        engine.endLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c67e5491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input():\n",
    "    with sr.Microphone() as source:\n",
    "        #print(\"Say something!!!\");\n",
    "        bot_speaking(\"Hey mate say something\")\n",
    "        audio=r.listen(source,timeout=0)\n",
    "        #print(\"Perfect, Thanks!\")\n",
    "        bot_speaking(\"Perfect, Thanks!\")\n",
    "    try:\n",
    "        msg=r.recognize_google(audio)\n",
    "        print(\"TEXT: \"+msg); #r.recognize(audio,language='hi-IN')\n",
    "        bot_speaking(\"you said \"+msg)\n",
    "        return msg\n",
    "    except:\n",
    "        #print(\"Dude it's not working :(\")\n",
    "        bot_speaking(\"Sorry mate! It's not working\")\n",
    "        pass;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea286c",
   "metadata": {},
   "source": [
    "# CHAT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "426e7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(inp_x, words):\n",
    "    # Create a bag of words representation for the input\n",
    "    # You may need to modify this function to match your preprocessing logic\n",
    "    input_data = bag_of_words(inp_x, words)\n",
    "\n",
    "    # Convert the input data to a numpy array and reshape it to match the model's input shape\n",
    "    input_data = np.array(input_data).reshape(1, -1)  # Reshape to (1, len(words))\n",
    "\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7a675be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a44a76c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VNR :Hi! I am your personal bot. I am here to answer queries on VNRVJIET\n",
      "YOU : tell me about canteen\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "VNR : VNRVJIET has canteen with variety of food available ,types of stalls like \n",
      " 1)fast food \n",
      "2)bakery \n",
      "3)soft drinks \n",
      "4)Regular meals \n",
      "5)coffee shop \n",
      "6)cafeteria\n",
      "YOU : tell me about hostel\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "VNR :  VNRVJIET has well-designed state-of-the-art hostels both for boys and girls.\n",
      "It has lot of facilities from hot water to gym and sport facilities.\n",
      " Visit http://vnrvjiet.ac.in/hostel.php\n",
      "YOU : tell about departments in vnrvjiet\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "VNR : A Student at vnr can be admitted in 3 ways 1)A-cat(eamcet,spot admissions) 2)B-cat(jee main) 3)Nri(12th marks).Last year cutoff ranks are provided for reference http://www.vnrvjiet.ac.in/download/admissions/FIRST_LAST_EAMCET_2019_RANKS.pdf\n",
      "YOU : quit\n"
     ]
    }
   ],
   "source": [
    "def chat():\n",
    "    print(\"VNR :Hi! I am your personal bot. I am here to answer queries on VNRVJIET\")\n",
    "    while True:\n",
    "        #inp=str(get_input())\n",
    "        inp=input(\"YOU : \")\n",
    "        if inp.lower() == \"quit\"or inp==None:\n",
    "            break\n",
    "        inp_x = word_checker(inp)\n",
    "        input_data = prepare_input(inp_x, words)\n",
    "        results = model.predict(input_data)[0]\n",
    "        results_index = numpy.argmax(results)\n",
    "        tag = labels[results_index]\n",
    "        #print(results[results_index])\n",
    "        if results[results_index] >= 0.9:\n",
    "            for tg in data[\"intents\"]:\n",
    "                if tg['tag'] == tag:\n",
    "                    responses = tg['responses']\n",
    "                    ms= random.choice(responses)\n",
    "                    print(\"VNR : \"+ms)\n",
    "                    bot_speaking(ms)\n",
    "        else:\n",
    "            print(\"VNR : Sorry, I don't know how to answer that yet \")\n",
    "            bot_speaking(\"Sorry, I don't know how to answer that yet\")\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0807b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Hari\n",
      "[nltk_data]     Priya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f360347",
   "metadata": {},
   "source": [
    "# GUI APPLICATION - CHATBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47c31b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "\n",
    "BG_GRAY = \"#ABB2B9\"\n",
    "BG_COLOR = \"#17202A\"\n",
    "TEXT_COLOR = \"#EAECEE\"\n",
    "\n",
    "FONT = \"Helvetica 14\"\n",
    "FONT_BOLD = \"Helvetica 13 bold\"\n",
    "bot_name =\"VNR-BOT\"\n",
    "def get_response(msg):\n",
    "    #print(\"Hi! I am your personal bot. I am here to answer queries on VNRVJIET\")\n",
    "    while True:\n",
    "        inp=msg\n",
    "        if inp.lower() == \"quit\"or inp==None:\n",
    "            break\n",
    "        inp_x = word_checker(inp)\n",
    "        input_data = prepare_input(inp_x, words)\n",
    "        results = model.predict(input_data)[0]\n",
    "#         results = model.predict([bag_of_words(inp_x, words)])[0]\n",
    "        results_index = numpy.argmax(results)\n",
    "        tag = labels[results_index]\n",
    "        #print(results[results_index])\n",
    "        if results[results_index] >= 0.9:\n",
    "            for tg in data[\"intents\"]:\n",
    "                if tg['tag'] == tag:\n",
    "                    responses = tg['responses']\n",
    "                    ms= random.choice(responses)\n",
    "                    return ms\n",
    "        else:\n",
    "            return \" Sorry, I don't know how to answer that yet \"\n",
    "\n",
    "class ChatApplication:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.window = Tk()\n",
    "        self._setup_main_window()\n",
    "        \n",
    "    def run(self):\n",
    "        self.window.mainloop()\n",
    "        \n",
    "    def _setup_main_window(self):\n",
    "        self.window.title(\"Chat\")\n",
    "        #self.window.resizable(width=False, height=False)\n",
    "        self.window.configure(width=470, height=550, bg=BG_COLOR)\n",
    "        \n",
    "        # head label\n",
    "        head_label = Label(self.window, bg=BG_COLOR, fg=TEXT_COLOR,\n",
    "                           text=\"WELCOME TO VNRVJIET CHAT-BOT\", font=FONT_BOLD, pady=10)\n",
    "        head_label.place(relwidth=1)\n",
    "        \n",
    "        # tiny divider\n",
    "        line = Label(self.window, width=450, bg=BG_GRAY)\n",
    "        line.place(relwidth=1, rely=0.07, relheight=0.012)\n",
    "        \n",
    "        # text widget\n",
    "        self.text_widget = Text(self.window, width=20, height=2, bg=BG_COLOR, fg=TEXT_COLOR,\n",
    "                                font=FONT, padx=5, pady=5)\n",
    "        self.text_widget.place(relheight=0.745, relwidth=1, rely=0.08)\n",
    "        self.text_widget.configure(cursor=\"arrow\", state=DISABLED)\n",
    "        \n",
    "        # scroll bar\n",
    "        scrollbar = Scrollbar(self.text_widget)\n",
    "        scrollbar.place(relheight=1, relx=0.974)\n",
    "        scrollbar.configure(command=self.text_widget.yview)\n",
    "        \n",
    "        # bottom label\n",
    "        bottom_label = Label(self.window, bg=BG_GRAY, height=80)\n",
    "        bottom_label.place(relwidth=1, rely=0.825)\n",
    "        \n",
    "        # message entry box\n",
    "        self.msg_entry = Entry(bottom_label, bg=\"#2C3E50\", fg=TEXT_COLOR, font=FONT)\n",
    "        self.msg_entry.place(relwidth=0.74, relheight=0.06, rely=0.008, relx=0.011)\n",
    "        self.msg_entry.focus()\n",
    "        self.msg_entry.bind(\"<Return>\", self._on_enter_pressed)\n",
    "        \n",
    "        # send button\n",
    "        send_button = Button(bottom_label, text=\"Send\", font=FONT_BOLD, width=20, bg=BG_GRAY, command=lambda: self._on_enter_pressed(None))\n",
    "        send_button.place(relx=0.77, rely=0.008, relheight=0.06, relwidth=0.22)\n",
    "     \n",
    "    def _on_enter_pressed(self, event):\n",
    "        msg = self.msg_entry.get()\n",
    "        self._insert_message(msg, \"You\")\n",
    "        \n",
    "    def _insert_message(self, msg, sender):\n",
    "        if not msg:\n",
    "            return\n",
    "        \n",
    "        self.msg_entry.delete(0, END)\n",
    "        msg1 = f\"{sender}: {msg}\\n\\n\"\n",
    "        self.text_widget.configure(state=NORMAL)\n",
    "        self.text_widget.insert(END, msg1)\n",
    "        self.text_widget.configure(state=DISABLED)\n",
    "        \n",
    "        msg2 = f\"{bot_name}: {get_response(msg)}\\n\\n\"\n",
    "        bot_speaking(get_response(msg))\n",
    "        self.text_widget.configure(state=NORMAL)\n",
    "        self.text_widget.insert(END, msg2)\n",
    "        self.text_widget.configure(state=DISABLED)\n",
    "        \n",
    "        self.text_widget.see(END)\n",
    "             \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    app = ChatApplication()\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d625b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
